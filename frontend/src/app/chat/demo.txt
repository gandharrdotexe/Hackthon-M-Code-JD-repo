import Ionicons from '@expo/vector-icons/Ionicons';
import { Audio } from 'expo-av';
import { router, useLocalSearchParams } from 'expo-router';
import * as Speech from 'expo-speech';
import { useCallback, useEffect, useMemo, useRef, useState } from 'react';
import {
    Animated,
    Easing,
    Image,
    Linking,
    ScrollView,
    StyleSheet,
    Text,
    TextInput,
    TouchableOpacity,
    View,
} from 'react-native';
import Markdown from 'react-native-markdown-display';
import { SafeAreaView } from 'react-native-safe-area-context';

import { OnboardingPalette, getSubjectDefinition } from '@/constants/onboarding';
import { useLanguage } from '@/contexts/language';
import { useQAModel } from '@/hooks/useQAModel';
import { supabase } from '@/lib/supabase';

type OnlineImage = {
  title: string;
  imageUrl: string;
  pageUrl: string;
  thumbnailUrl?: string;
};

type OnlineVideo = {
  videoId: string;
  title: string;
  url: string;
  channelTitle?: string;
  publishedAt?: string;
};

type OnlineSource = {
  title: string;
  url: string;
};

type Message = {
  id: string;
  role: 'user' | 'assistant';
  text: string;
  attachments?: {
    images?: OnlineImage[];
    videos?: OnlineVideo[];
    sources?: OnlineSource[];
  };
};

const offlineSeedConversation: Message[] = [
  {
    id: '1',
    role: 'user',
    text: "Explain Newton's first law of motion.",
  },
  {
    id: '2',
    role: 'assistant',
    text: "Newton's First Law of Motion, also known as the law of inertia, states that an object will remain at rest or in uniform motion in a straight line unless acted upon by an external force.",
  },
  {
    id: '3',
    role: 'user',
    text: 'What about the second law?',
  },
  {
    id: '4',
    role: 'assistant',
    text: 'The second law states that the acceleration of an object is directly proportional to the net force acting upon it and inversely proportional to its mass (F = ma).',
  },
];

const onlineSeedConversation: Message[] = [
 
];

export default function SubjectAssistantScreen() {
  const { subjectId } = useLocalSearchParams<{ subjectId?: string }>();
  const { copy } = useLanguage();
  const subjectCopy = copy.subject;
  const [prompt, setPrompt] = useState('');
  const [offlineMode, setOfflineMode] = useState(true);
  const [offlineHistory, setOfflineHistory] = useState<Message[]>(offlineSeedConversation);
  const [onlineHistory, setOnlineHistory] = useState<Message[]>(onlineSeedConversation);
  const [isResponding, setIsResponding] = useState(false);
  const [voiceError, setVoiceError] = useState<string | null>(null);
  const [isRecording, setIsRecording] = useState(false);
  const [isTranscribing, setIsTranscribing] = useState(false);
  const [chatError, setChatError] = useState<string | null>(null);
  const [classId, setClassId] = useState<string | null>(null);
  const [classLoadError, setClassLoadError] = useState<string | null>(null);
  const micScale = useRef(new Animated.Value(1)).current;
  const wavePulse = useRef(new Animated.Value(0)).current;
  const waveLoopRef = useRef<Animated.CompositeAnimation | null>(null);
  const recordingRef = useRef<Audio.Recording | null>(null);
  const typingDots = useRef([new Animated.Value(0.3), new Animated.Value(0.3), new Animated.Value(0.3)]).current;
  const typingLoopRef = useRef<Animated.CompositeAnimation[]>([]);

  const subjectDefinition = subjectId ? getSubjectDefinition(subjectId) : null;

  const pageTitle = useMemo(() => {
    if (!subjectDefinition) return 'Subject AI';
    return `${subjectDefinition.title} AI`;
  }, [subjectDefinition]);

  const { isReady: isOfflineReady, isLoading: isOfflineLoading, error: offlineDataError, findAnswer } = useQAModel(
    classId,
    subjectId ?? null,
  );

  const activeMessages = offlineMode ? offlineHistory : onlineHistory;
  const modeHintText = offlineMode ? subjectCopy.offlineHint : subjectCopy.onlineHint;
  const inputPlaceholder = offlineMode ? subjectCopy.offlinePlaceholder : subjectCopy.onlinePlaceholder;
  const isSendDisabled = !prompt.trim() || isResponding;

  useEffect(() => {
    let isMounted = true;

    const loadClassPreference = async () => {
      try {
        setClassLoadError(null);
        const {
          data: { user },
          error,
        } = await supabase.auth.getUser();
        if (error) throw error;
        if (!user?.id) throw new Error('Please log in again to access offline packs.');

        const { data, error: progressError } = await supabase
          .from('onboarding_progress')
          .select('class_id')
          .eq('user_id', user.id)
          .maybeSingle();

        if (progressError && progressError.code !== 'PGRST116') {
          throw progressError;
        }

        if (!isMounted) return;
        setClassId((data?.class_id ?? '8') as string);
      } catch (err) {
        if (!isMounted) return;
        setClassLoadError(err instanceof Error ? err.message : subjectCopy.loadPreferenceError);
      }
    };

    loadClassPreference();
    return () => {
      isMounted = false;
    };
  }, [subjectCopy.loadPreferenceError]);

  const offlineStatusText = useMemo(() => {
    if (!offlineMode) return null;
    if (classLoadError) return classLoadError;
    if (isOfflineLoading) return subjectCopy.offlineLoading;
    if (offlineDataError) return offlineDataError;
    if (!isOfflineReady) return subjectCopy.offlineUnavailable;
    return null;
  }, [classLoadError, isOfflineLoading, offlineDataError, isOfflineReady, offlineMode, subjectCopy.offlineLoading, subjectCopy.offlineUnavailable]);

  const handleModeChange = useCallback((mode: 'offline' | 'online') => {
    setOfflineMode(mode === 'offline');
    setPrompt('');
    setIsResponding(false);
  }, []);

  const fetchOnlineAnswer = useCallback(
    async (query: string): Promise<Message> => {
      const token = "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiIwNzI0MTZkMC0zOWFlLTQ4M2YtYmZhNy0yNTY4MjgxNWMwMGQiLCJpYXQiOjE3NjQxODY4ODQsImV4cCI6MTc2NTA1MDg4NH0.Hjhy7bUi9s3gQlXLyRrDkDK0ATK4LGaN64kSlOyXj90";
      if (!token) {
        throw new Error('Missing Lunnaa token. Set EXPO_PUBLIC_LUNNAA_TOKEN in your .env.');
      }

      const response = await fetch('https://lunnaa.vercel.app/api/proxy/chat/stream', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          Authorization: `Bearer ${token}`,
          Accept: 'text/event-stream',
        },
        body: JSON.stringify({ prompt: query, options: { includeYouTube: true, includeImageSearch: true } }),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(errorText || 'Unable to reach Lunnaa API.');
      }

      let aggregatedText = '';
      let images: OnlineImage[] = [];
      let videos: OnlineVideo[] = [];
      let sources: OnlineSource[] = [];

      const applyEventData = (eventType: string, dataLine: string) => {
        if (!dataLine) return;
        try {
          const parsed = JSON.parse(dataLine);
          switch (eventType) {
            case 'message':
              aggregatedText += parsed?.text ?? '';
              break;
            case 'images':
              images = parsed?.images ?? images;
              break;
            case 'youtubeResults':
              videos =
                parsed?.videos?.map((video: any) => ({
                  videoId: video.videoId,
                  title: video.title,
                  url: video.url ?? `https://www.youtube.com/watch?v=${video.videoId}`,
                  channelTitle: video.channelTitle,
                  publishedAt: video.publishedAt,
                })) ?? videos;
              break;
            case 'sources':
              sources = parsed?.sources ?? sources;
              break;
            default:
              break;
          }
        } catch (error) {
          console.warn('[online] event parse error', error);
        }
      };

      const processBufferChunks = (buffer: string) => {
        let workingBuffer = buffer;
        let boundary = workingBuffer.indexOf('\n\n');
        while (boundary > -1) {
          const chunk = workingBuffer.slice(0, boundary).trim();
          workingBuffer = workingBuffer.slice(boundary + 2);
          boundary = workingBuffer.indexOf('\n\n');
          if (!chunk) continue;

          let eventType = 'message';
          let dataLine = '';
          for (const line of chunk.split('\n')) {
            if (line.startsWith('event:')) {
              eventType = line.replace('event:', '').trim();
            } else if (line.startsWith('data:')) {
              dataLine += line.replace('data:', '').trim();
            }
          }

          applyEventData(eventType, dataLine);
        }
        return workingBuffer;
      };

      if (!response.body || typeof response.body.getReader !== 'function') {
        const payload = await response.text();
        const normalized = payload.replace(/\r\n/g, '\n');
        normalized
          .split('\n\n')
          .map((chunk) => chunk.trim())
          .filter(Boolean)
          .forEach((chunk) => {
            let eventType = 'message';
            let dataLine = '';
            for (const line of chunk.split('\n')) {
              if (line.startsWith('event:')) {
                eventType = line.replace('event:', '').trim();
              } else if (line.startsWith('data:')) {
                dataLine += line.replace('data:', '').trim();
              }
            }
            applyEventData(eventType, dataLine);
          });
      } else {
        const reader = response.body.getReader();
        const decoder = new TextDecoder('utf-8');
        let buffer = '';
        while (true) {
          const { value, done } = await reader.read();
          if (done) break;
          buffer += decoder.decode(value, { stream: true });
          buffer = processBufferChunks(buffer);
        }
        // process any trailing data without delimiter
        if (buffer.trim()) {
          processBufferChunks(`${buffer}\n\n`);
        }
      }

      if (!aggregatedText.trim()) {
        aggregatedText = 'I was unable to find an answer right now.';
      }

      return {
        id: `${Date.now()}-online-response`,
        role: 'assistant',
        text: aggregatedText.trim(),
        attachments: {
          images: images.length ? images : undefined,
          videos: videos.length ? videos : undefined,
          sources: sources.length ? sources : undefined,
        },
      };
    },
    [],
  );

  const handleSend = useCallback(() => {
    const trimmed = prompt.trim();
    if (!trimmed || isResponding) return;

    const newUserMessage: Message = {
      id: `${Date.now()}`,
      role: 'user',
      text: trimmed,
    };

    if (offlineMode) {
      const qaResult = findAnswer(trimmed);
      const fallbackText = offlineDataError ?? (isOfflineLoading ? subjectCopy.offlineLoading : subjectCopy.offlineNoAnswer);
      const offlineReply: Message = {
        id: `${Date.now()}-offline-reply`,
        role: 'assistant',
        text: qaResult
          ? qaResult.topic
            ? `**${qaResult.topic}**\n\n${qaResult.answer}`
            : qaResult.answer
          : fallbackText,
      };
      setOfflineHistory((prev) => [...prev, newUserMessage, offlineReply]);
    } else {
      setIsResponding(true);
      setChatError(null);
      setOnlineHistory((prev) => [...prev, newUserMessage]);
      fetchOnlineAnswer(trimmed)
        .then((assistantMessage) => {
          setOnlineHistory((prev) => [...prev, assistantMessage]);
        })
        .catch((error) => {
          console.error('[online] fetch error', error);
          setChatError(error instanceof Error ? error.message : 'Unable to fetch online answer.');
        })
        .finally(() => {
          setIsResponding(false);
        });
    }

    setPrompt('');
  }, [fetchOnlineAnswer, findAnswer, isOfflineLoading, offlineDataError, offlineMode, isResponding, prompt]);

  const animateMic = useCallback(() => {
    Animated.sequence([
      Animated.timing(micScale, {
        toValue: 1.15,
        duration: 120,
        easing: Easing.out(Easing.ease),
        useNativeDriver: true,
      }),
      Animated.spring(micScale, {
        toValue: 1,
        friction: 3,
        useNativeDriver: true,
      }),
    ]).start();
  }, [micScale]);

  const maxSpeechLength = (Speech as unknown as { maxSpeechInputLength?: number })?.maxSpeechInputLength ?? 3900;

  const speakText = useCallback(
    async (utterance: string, options?: Speech.SpeechOptions) => {
      setVoiceError(null);
      try {
        await Speech.stop();
        const truncatedUtterance =
          utterance.length > maxSpeechLength ? `${utterance.slice(0, maxSpeechLength - 1)}â€¦` : utterance;
        Speech.speak(truncatedUtterance, {
          ...options,
          rate: options?.rate ?? 1,
          pitch: options?.pitch ?? 1,
          onStart: () => {
            console.log('[speech] onStart');
            options?.onStart?.();
          },
          onDone: () => {
            console.log('[speech] onDone');
            options?.onDone?.();
          },
          onStopped: () => {
            console.log('[speech] onStopped');
            options?.onStopped?.();
          },
          onError: (event) => {
            console.error('[speech] onError', event);
            setVoiceError(typeof event === 'string' ? event : event?.message ?? 'Unable to play audio.');
            options?.onError?.(event as never);
          },
        });
      } catch (error) {
        console.error('[speech] exception', error);
        setVoiceError(error instanceof Error ? error.message : 'Unable to trigger text-to-speech.');
      }
    },
    [maxSpeechLength],
  );

  const startWaveAnimation = useCallback(() => {
    waveLoopRef.current?.stop();
    waveLoopRef.current = Animated.loop(
      Animated.sequence([
        Animated.timing(wavePulse, {
          toValue: 1,
          duration: 500,
          easing: Easing.out(Easing.ease),
          useNativeDriver: true,
        }),
        Animated.timing(wavePulse, {
          toValue: 0,
          duration: 500,
          easing: Easing.in(Easing.ease),
          useNativeDriver: true,
        }),
      ]),
    );
    waveLoopRef.current.start();
  }, [wavePulse]);

  const stopWaveAnimation = useCallback(() => {
    waveLoopRef.current?.stop();
    wavePulse.setValue(0);
  }, [wavePulse]);

  useEffect(() => {
    typingLoopRef.current.forEach((anim) => anim.stop());
    typingLoopRef.current = [];

    if (isResponding && !offlineMode) {
      typingDots.forEach((dot, index) => {
        const sequence = Animated.sequence([
          Animated.delay(index * 120),
          Animated.timing(dot, {
            toValue: 1,
            duration: 360,
            useNativeDriver: true,
          }),
          Animated.timing(dot, {
            toValue: 0.3,
            duration: 360,
            useNativeDriver: true,
          }),
        ]);
        const loop = Animated.loop(sequence);
        typingLoopRef.current.push(loop);
        loop.start();
      });
    } else {
      typingDots.forEach((dot) => dot.setValue(0.3));
    }

    return () => {
      typingLoopRef.current.forEach((anim) => anim.stop());
      typingLoopRef.current = [];
    };
  }, [isResponding, offlineMode, typingDots]);

  const startRecording = useCallback(async () => {
    try {
      setVoiceError(null);
      const permission = await Audio.requestPermissionsAsync();
      if (!permission.granted) {
        setVoiceError('Microphone permission is required.');
        return;
      }

      await Audio.setAudioModeAsync({ allowsRecordingIOS: true, playsInSilentModeIOS: true });
      const recording = new Audio.Recording();
      await recording.prepareToRecordAsync(Audio.RecordingOptionsPresets.HIGH_QUALITY);
      await recording.startAsync();
      recordingRef.current = recording;
      setIsRecording(true);
      startWaveAnimation();
      animateMic();
    } catch (error) {
      console.error('[recording] start:error', error);
      setVoiceError(error instanceof Error ? error.message : 'Unable to start recording.');
    }
  }, [animateMic, startWaveAnimation]);

  const stopRecordingAndTranscribe = useCallback(async () => {
    const recording = recordingRef.current;
    if (!recording) return;

    try {
      setIsRecording(false);
      setIsTranscribing(true);
      await recording.stopAndUnloadAsync();
      const uri = recording.getURI();
      recordingRef.current = null;
      if (!uri) {
        throw new Error('No recording data found.');
      }

      const response = await fetch(uri);
      const audioBlob = await response.blob();

      const deepgramKey = "b0c3e3948041ea483954cac7a74e755fcdaf98c8";
      if (!deepgramKey) {
        throw new Error('Missing Deepgram key. Set EXPO_PUBLIC_DEEPGRAM_KEY in your .env.');
      }

      const deepgramResponse = await fetch('https://api.deepgram.com/v1/listen', {
        method: 'POST',
        headers: {
          Authorization: `Token ${deepgramKey}`,
          'Content-Type': 'audio/wav',
        },
        body: audioBlob,
      });

      if (!deepgramResponse.ok) {
        const errorText = await deepgramResponse.text();
        throw new Error(`Deepgram error ${deepgramResponse.status}: ${errorText}`);
      }

      const deepgramJson = await deepgramResponse.json();
      const transcript =
        deepgramJson?.results?.channels?.[0]?.alternatives?.[0]?.transcript?.trim() ?? '';

      if (transcript) {
        setPrompt((prev) => (prev ? `${prev} ${transcript}` : transcript));
      } else {
        setVoiceError('No speech detected. Try again.');
      }
    } catch (error) {
      console.error('[recording] stop:error', error);
      setVoiceError(error instanceof Error ? error.message : 'Unable to transcribe audio.');
    } finally {
      stopWaveAnimation();
      setIsTranscribing(false);
      recordingRef.current = null;
    }
  }, [stopWaveAnimation]);

  const handleMicPress = useCallback(() => {
    if (isRecording) {
      stopRecordingAndTranscribe();
    } else {
      startRecording();
    }
  }, [isRecording, startRecording, stopRecordingAndTranscribe]);

  const handleListen = useCallback(
    (messageText: string) => {
      speakText(messageText, { rate: 1, pitch: 1 });
    },
    [speakText],
  );

  const handleOpenLink = useCallback((url?: string) => {
    if (!url) return;
    Linking.openURL(url).catch((error) => console.warn('[link] open error', error));
  }, []);

  const micStatusMessage = isRecording
    ? subjectCopy.offlineModeLabel
    : isTranscribing
      ? subjectCopy.onlineModeLabel
      : null;
